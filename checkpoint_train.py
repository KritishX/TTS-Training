# ===== ULTIMATE FIX V3: VITS TRAINING WITH CHECKPOINT RESUME =====
# Fixes: ZeroDivisionError, log file creation, folder cleanup, resume training

import os
import sys
import glob
import torch
from pathlib import Path

# ===== CONFIGURATION =====
BASE = r"C:\Users\ReticleX\Pictures\nepali_tts"  
OUTPUT = os.path.join(BASE, "vits_output_v5")  # NEW output folder
os.makedirs(OUTPUT, exist_ok=True)

print("=" * 70)
print("VITS TTS Training - FINAL FIX V3 (All Errors Resolved, Resume Checkpoint)")
print("=" * 70)

# ===== CRITICAL FIX 1: Force torchaudio backend =====
import torchaudio
try:
    torchaudio.set_audio_backend("soundfile")
except:
    pass

# ===== CRITICAL FIX 2: Patch Trainer COMPREHENSIVELY =====
print("\nüîß Applying comprehensive patches...")

import trainer
from trainer import Trainer, TrainerArgs
import trainer.generic_utils

# Disable logger initialization
def _disabled_init_logger(self):
    self.logger = None
    self.dashboard_logger = None
Trainer._init_logger = _disabled_init_logger

# Disable folder removal
def _disabled_remove(*args, **kwargs):
    pass
trainer.generic_utils.remove_experiment_folder = _disabled_remove
if hasattr(trainer, 'remove_experiment_folder'):
    trainer.remove_experiment_folder = _disabled_remove

# Safe checkpoint saving
original_save = Trainer.save_checkpoint
def safe_save_checkpoint(self):
    try:
        model_to_save = self.model[0] if isinstance(self.model, list) else self.model
        checkpoint = {
            'model': model_to_save.state_dict(),
            'step': self.total_steps_done,
            'epoch': self.epochs_done,
        }
        try:
            if hasattr(self, 'optimizer'):
                if isinstance(self.optimizer, list):
                    checkpoint['optimizer'] = [opt.state_dict() for opt in self.optimizer]
                else:
                    checkpoint['optimizer'] = self.optimizer.state_dict()
        except:
            pass
        checkpoint_path = os.path.join(self.output_path, f"checkpoint_{self.epochs_done}.pth")
        torch.save(checkpoint, checkpoint_path)
        print(f"\n > CHECKPOINT: {checkpoint_path}")
        return checkpoint_path
    except Exception as e:
        print(f"‚ö†Ô∏è Checkpoint save error: {e}")
        return None
Trainer.save_checkpoint = safe_save_checkpoint

# Override fit method
original_fit = Trainer.fit
def safe_fit(self):
    try:
        self._fit()
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Training interrupted by user")
        self.save_checkpoint()
    except Exception as e:
        print(f"\n‚ùå Training error: {e}")
        print("üíæ Saving emergency checkpoint...")
        try:
            self.save_checkpoint()
            print("‚úÖ Checkpoint saved")
        except Exception as save_err:
            print(f"‚ö†Ô∏è Could not save: {save_err}")
        raise
Trainer.fit = safe_fit

print("‚úÖ All patches applied")

# ===== IMPORT TTS MODULES =====
print("\nüì¶ Importing TTS modules...")
try:
    from TTS.config.shared_configs import BaseDatasetConfig, BaseAudioConfig
    from TTS.tts.configs.vits_config import VitsConfig
    from TTS.tts.models.vits import Vits
    from TTS.tts.utils.text.tokenizer import TTSTokenizer
    from TTS.tts.utils.text.characters import Graphemes
    from TTS.utils.audio import AudioProcessor
    from TTS.tts.datasets import load_tts_samples
    print("‚úÖ All imports successful")
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    sys.exit(1)

# ===== STEP 1: CREATE NEPALI CHARACTER SET =====
print("\nüî§ Creating Nepali character set...")
nepali_vocab = [
    '‡§Ö','‡§Ü','‡§á','‡§à','‡§â','‡§ä','‡§ã','‡§è','‡§ê','‡§ì','‡§î',
    '‡§ï','‡§ñ','‡§ó','‡§ò','‡§ô','‡§ö','‡§õ','‡§ú','‡§ù','‡§û',
    '‡§ü','‡§†','‡§°','‡§¢','‡§£','‡§§','‡§•','‡§¶','‡§ß','‡§®',
    '‡§™','‡§´','‡§¨','‡§≠','‡§Æ','‡§Ø','‡§∞','‡§≤','‡§µ','‡§∂','‡§∑','‡§∏','‡§π',
    '‡§æ','‡§ø','‡•Ä','‡•Å','‡•Ç','‡•É','‡•á','‡•à','‡•ã','‡•å','‡•ç',
    '‡§Ç','‡§É','‡§Å',
    '‡•¶','‡•ß','‡•®','‡•©','‡•™','‡•´','‡•¨','‡•≠','‡•Æ','‡•Ø'
] + list("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789") \
  + list(" !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~‡•§")
nepali_vocab = sorted(set(nepali_vocab))

chars_obj = Graphemes(
    characters=nepali_vocab,
    punctuations="‡•§!?,.:; -\"",
    pad="_", eos="~", bos="^", blank="#",
)

tokenizer = TTSTokenizer(use_phonemes=False, characters=chars_obj, add_blank=True)
print(f"‚úÖ Tokenizer ready (vocab: {len(tokenizer.characters.characters)})")

# ===== STEP 2: DATASET CONFIGURATION =====
print("\nüìä Setting up dataset...")
dataset_config = BaseDatasetConfig(
    formatter="ljspeech",
    meta_file_train=os.path.join(BASE, "dataset", "ljspeech_train", "metadata.csv"),
    meta_file_val=os.path.join(BASE, "dataset", "ljspeech_val", "metadata.csv"),
    path=os.path.join(BASE, "dataset", "ljspeech_train"),
    language="ne",
)

# ===== STEP 3: LOAD DATASET SAMPLES =====
print("\nüìÇ Loading dataset samples...")
train_samples, eval_samples = load_tts_samples(
    [dataset_config],
    eval_split=True,
    eval_split_max_size=256,
    eval_split_size=0.15,
)
print(f"‚úÖ Data loaded: {len(train_samples)} train / {len(eval_samples)} val")

# ===== STEP 4: AUDIO CONFIGURATION =====
print("\nüéµ Creating audio config...")
audio_config = BaseAudioConfig(
    sample_rate=22050,
    hop_length=256,
    win_length=1024,
    fft_size=1024,
    num_mels=80,
    mel_fmin=0.0,
    mel_fmax=8000.0,
)
ap = AudioProcessor.init_from_config(audio_config)
print(f"‚úÖ Audio processor ready: {ap.sample_rate} Hz")

# ===== STEP 5: VITS CONFIGURATION =====
print("\n‚öôÔ∏è Creating VITS config...")
config = VitsConfig()
config.audio = audio_config
config.output_path = OUTPUT
config.run_name = "nepali_vits"
config.datasets = [dataset_config]

config.batch_size = 4
config.eval_batch_size = 2
config.num_loader_workers = 0
config.num_eval_loader_workers = 0
config.epochs = 100
config.text_cleaner = "basic_cleaners"
config.use_phonemes = False
config.add_blank = True
config.characters = None
config.num_chars = len(tokenizer.characters.characters)
config.optimizer = "AdamW"
config.optimizer_params = {"betas": [0.8, 0.99], "eps": 1e-9, "weight_decay": 0.01}
config.lr = 2e-4
config.lr_scheduler = "ExponentialLR"
config.lr_scheduler_params = {"gamma": 0.999875}
config.print_step = 50
config.save_step = 1000
config.save_n_checkpoints = 5
config.run_eval = True
config.plot_step = 999999
config.dashboard_logger = "tensorboard"
config.test_sentences = ["‡§®‡§Æ‡§∏‡•ç‡§§‡•á", "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶"]

print("‚úÖ Config created")

# ===== STEP 6: CREATE MODEL =====
print("\nü§ñ Creating VITS model...")
model = Vits(config=config, ap=ap, tokenizer=tokenizer, speaker_manager=None)
device_str = "CPU"
if torch.cuda.is_available():
    model.cuda()
    device_str = f"GPU ({torch.cuda.get_device_name(0)})"

print(f"‚úÖ Model ready on {device_str}")
print(f"   Parameters: {sum(p.numel() for p in model.parameters()):,}")

# ===== STEP 7A: CHECK FOR EXISTING CHECKPOINT =====
checkpoint_files = glob.glob(os.path.join(OUTPUT, "checkpoint_*.pth"))
restore_path = max(checkpoint_files, key=os.path.getmtime) if checkpoint_files else None
if restore_path:
    print(f"‚úÖ Resuming training from checkpoint: {restore_path}")
else:
    print("‚ÑπÔ∏è No checkpoints found, starting from scratch")

# ===== STEP 7B: CREATE TRAINER =====
trainer_args = TrainerArgs()
trainer_args.continue_path = restore_path
trainer_args.restore_path = None
trainer_args.best_path = None

trainer_obj = Trainer(
    trainer_args,
    config,
    OUTPUT,
    model=model,
    train_samples=train_samples,
    eval_samples=eval_samples,
)

print("‚úÖ Trainer ready")

# ===== STEP 8: START TRAINING =====
print("\n" + "=" * 70)
print("STARTING TRAINING")
print("=" * 70)
print(f"\nüìä Training Configuration:")
print(f"   Dataset: {len(train_samples)} train, {len(eval_samples)} val samples")
print(f"   Epochs: {config.epochs}")
print(f"   Batch size: {config.batch_size}")
print(f"   Device: {device_str}")
print(f"   Output: {OUTPUT}")
print(f"   Checkpoints: Every {config.save_step} steps")
print(f"\nüí° Monitor training: tensorboard --logdir={OUTPUT}")
print("\n" + "-" * 70 + "\n")

try:
    trainer_obj.fit()
    print("\n" + "=" * 70)
    print("üéâ TRAINING COMPLETED SUCCESSFULLY!")
    print("=" * 70)
except KeyboardInterrupt:
    print("\n‚ö†Ô∏è  Training interrupted - handled by patched trainer")
except Exception as e:
    print(f"\n‚ùå Error caught: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 70)
print("SCRIPT FINISHED")
print("=" * 70)
