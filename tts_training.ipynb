{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20781cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VITS TTS Dependencies installed for TRAINING - COMPLETE WORKING VERSION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===== COMPLETE WORKING VITS TRAINING SCRIPT =====\n",
    "\n",
    "# Define base directories\n",
    "import os\n",
    "BASE = r\"C:\\Users\\ReticleX\\Pictures\\nepali_tts\"  \n",
    "OUTPUT = os.path.join(BASE, \"vits_output_v2\")\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import logging\n",
    "print(\"=\" * 70)\n",
    "print(\"VITS TTS Dependencies installed for TRAINING - COMPLETE WORKING VERSION\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d765ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchaudio version: 2.9.1+cpu\n",
      "has set_audio_backend: False\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "print(\"torchaudio version:\", torchaudio.__version__)\n",
    "print(\"has set_audio_backend:\", hasattr(torchaudio, \"set_audio_backend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327303bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Importing modules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ReticleX\\.conda\\envs\\TTS\\lib\\site-packages\\librosa\\core\\intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# ===== STEP 2: IMPORTS =====\n",
    "print(\"\\nüì¶ Importing modules...\")\n",
    "try:\n",
    "    from TTS.config.shared_configs import BaseDatasetConfig\n",
    "    from TTS.tts.configs.vits_config import VitsConfig\n",
    "    from TTS.tts.models.vits import Vits\n",
    "    from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "    from TTS.tts.utils.text.characters import Graphemes\n",
    "    from TTS.utils.audio import AudioProcessor\n",
    "    from TTS.tts.datasets import load_tts_samples\n",
    "    from trainer import Trainer, TrainerArgs\n",
    "    print(\"‚úÖ All imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"\\nüí° Install TTS: pip install TTS\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e25f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42b59bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Creating Nepali character set...\n",
      "‚úÖ Character set ready (164 characters)\n",
      "‚úÖ Tokenizer ready (vocab: 164)\n",
      "   Test: '‡§®‡§Æ‡§∏‡•ç‡§§‡•á' ‚Üí 13 tokens ‚Üí '#‡§®#‡§Æ#‡§∏#‡•ç#‡§§#‡•á#'\n"
     ]
    }
   ],
   "source": [
    "# ===== STEP 3: CREATE NEPALI CHARACTER SET =====\n",
    "print(\"\\nüìù Creating Nepali character set...\")\n",
    "\n",
    "nepali_vocab = []\n",
    "\n",
    "# Vowels\n",
    "vowels = ['‡§Ö', '‡§Ü', '‡§á', '‡§à', '‡§â', '‡§ä', '‡§ã', '‡§è', '‡§ê', '‡§ì', '‡§î']\n",
    "nepali_vocab.extend(vowels)\n",
    "\n",
    "# Consonants\n",
    "consonants = [\n",
    "    '‡§ï', '‡§ñ', '‡§ó', '‡§ò', '‡§ô',\n",
    "    '‡§ö', '‡§õ', '‡§ú', '‡§ù', '‡§û',\n",
    "    '‡§ü', '‡§†', '‡§°', '‡§¢', '‡§£',\n",
    "    '‡§§', '‡§•', '‡§¶', '‡§ß', '‡§®',\n",
    "    '‡§™', '‡§´', '‡§¨', '‡§≠', '‡§Æ',\n",
    "    '‡§Ø', '‡§∞', '‡§≤', '‡§µ', '‡§∂', '‡§∑', '‡§∏', '‡§π'\n",
    "]\n",
    "nepali_vocab.extend(consonants)\n",
    "\n",
    "# Vowel signs\n",
    "vowel_signs = ['‡§æ', '‡§ø', '‡•Ä', '‡•Å', '‡•Ç', '‡•É', '‡•á', '‡•à', '‡•ã', '‡•å', '‡•ç']\n",
    "nepali_vocab.extend(vowel_signs)\n",
    "\n",
    "# Diacritics\n",
    "diacritics = ['‡§Ç', '‡§É', '‡§Å']\n",
    "nepali_vocab.extend(diacritics)\n",
    "\n",
    "# Nepali digits\n",
    "digits = ['‡•¶', '‡•ß', '‡•®', '‡•©', '‡•™', '‡•´', '‡•¨', '‡•≠', '‡•Æ', '‡•Ø']\n",
    "nepali_vocab.extend(digits)\n",
    "\n",
    "# Latin alphabet and numbers\n",
    "latin = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\")\n",
    "nepali_vocab.extend(latin)\n",
    "\n",
    "# Common punctuation\n",
    "common_punct = list(\" !\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~‡•§\")\n",
    "nepali_vocab.extend(common_punct)\n",
    "\n",
    "# Remove duplicates and sort\n",
    "nepali_vocab = sorted(set(nepali_vocab))\n",
    "\n",
    "print(f\"‚úÖ Character set ready ({len(nepali_vocab)} characters)\")\n",
    "\n",
    "# Create Graphemes object\n",
    "chars_obj = Graphemes(\n",
    "    characters=nepali_vocab,\n",
    "    punctuations=\"‡•§!?,.:; -\\\"\",\n",
    "    pad=\"_\",\n",
    "    eos=\"~\",\n",
    "    bos=\"^\",\n",
    "    blank=\"#\",\n",
    ")\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = TTSTokenizer(\n",
    "    use_phonemes=False,\n",
    "    characters=chars_obj,\n",
    "    add_blank=True,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Tokenizer ready (vocab: {len(tokenizer.characters.characters)})\")\n",
    "\n",
    "# Test tokenizer\n",
    "test_text = \"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\"\n",
    "test_ids = tokenizer.text_to_ids(test_text)\n",
    "test_decoded = tokenizer.ids_to_text(test_ids)\n",
    "print(f\"   Test: '{test_text}' ‚Üí {len(test_ids)} tokens ‚Üí '{test_decoded}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297deebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Setting up dataset...\n"
     ]
    }
   ],
   "source": [
    "# ===== STEP 4: DATASET CONFIGURATION =====\n",
    "print(\"\\nüìä Setting up dataset...\")\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\",\n",
    "    meta_file_train=os.path.join(BASE, \"dataset\", \"ljspeech_train\", \"metadata.csv\"),\n",
    "    meta_file_val=os.path.join(BASE, \"dataset\", \"ljspeech_val\", \"metadata.csv\"),\n",
    "    path=os.path.join(BASE, \"dataset\", \"ljspeech_train\"),\n",
    "    language=\"ne\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b1f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading dataset samples...\n",
      " | > Found 6082 files in C:\\Users\\ReticleX\\Pictures\\nepali_tts\\dataset\\ljspeech_train\n",
      "‚úÖ Data loaded:\n",
      "   Training samples: 6082\n",
      "   Validation samples: 1065\n"
     ]
    }
   ],
   "source": [
    "# ===== STEP 6: LOAD DATASET SAMPLES =====\n",
    "print(\"\\nüìÇ Loading dataset samples...\")\n",
    "\n",
    "try:\n",
    "    # Load training samples\n",
    "    train_samples, eval_samples = load_tts_samples(\n",
    "        [dataset_config],\n",
    "        eval_split=True,\n",
    "        eval_split_max_size=256,\n",
    "        eval_split_size=0.15,\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Data loaded:\")\n",
    "    print(f\"   Training samples: {len(train_samples)}\")\n",
    "    print(f\"   Validation samples: {len(eval_samples)}\")\n",
    "    \n",
    "    if len(train_samples) == 0:\n",
    "        raise Exception(\"No training samples found!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    print(\"\\nüí° Check:\")\n",
    "    print(f\"   1. File exists: {dataset_config.meta_file_train}\")\n",
    "    print(f\"   2. Audio files exist in: {dataset_config.path}\")\n",
    "    print(f\"   3. Format: filename|text (LJSpeech format)\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d321da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéµ Creating audio config (FIXED)...\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      "‚úÖ Audio processor: 22050 Hz\n",
      "‚úÖ Config created with proper audio config\n",
      "‚úÖ Model ready (83,068,204 params)\n",
      "\n",
      "üîß Configuring logging to disable file output...\n",
      "‚úÖ Logging configured for console output only\n",
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Num. of CPUs: 16\n",
      " | > Num. of Torch Threads: 12\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=C:\\Users\\ReticleX\\Pictures\\nepali_tts\\vits_output_v2\\nepali_vits-December-17-2025_10+42AM-0000000\n",
      "\n",
      " > Model has 83068204 parameters\n"
     ]
    }
   ],
   "source": [
    "# ===== CRITICAL FIX: Use BaseAudioConfig instead of dict =====\n",
    "# Replace your audio config creation with this:\n",
    "\n",
    "from TTS.config.shared_configs import BaseAudioConfig\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "print(\"\\nüéµ Creating audio config (FIXED)...\")\n",
    "\n",
    "# CORRECT: Use BaseAudioConfig object, not dict\n",
    "audio_config = BaseAudioConfig(\n",
    "    sample_rate=22050,\n",
    "    hop_length=256,\n",
    "    win_length=1024,\n",
    "    fft_size=1024,\n",
    "    num_mels=80,\n",
    "    mel_fmin=0.0,\n",
    "    mel_fmax=8000.0,\n",
    ")\n",
    "\n",
    "# Create audio processor from config\n",
    "ap = AudioProcessor.init_from_config(audio_config)\n",
    "print(f\"‚úÖ Audio processor: {ap.sample_rate} Hz\")\n",
    "\n",
    "# Now when you create VitsConfig:\n",
    "config = VitsConfig()\n",
    "config.audio = audio_config  # This is now a proper object, not a dict!\n",
    "config.output_path = OUTPUT\n",
    "config.run_name = \"nepali_vits\"\n",
    "\n",
    "# Set other attributes\n",
    "config.datasets = [dataset_config]\n",
    "config.batch_size = 4\n",
    "config.eval_batch_size = 2\n",
    "config.num_loader_workers = 0\n",
    "config.num_eval_loader_workers = 0\n",
    "config.epochs = 100\n",
    "config.text_cleaner = \"basic_cleaners\"\n",
    "config.use_phonemes = False\n",
    "config.add_blank = True\n",
    "config.characters = None\n",
    "config.num_chars = len(tokenizer.characters.characters)\n",
    "config.lr = 2e-4\n",
    "config.print_step = 25\n",
    "config.save_step = 1000\n",
    "config.save_n_checkpoints = 5\n",
    "config.run_eval = True\n",
    "config.test_sentences = [\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\", \"‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶\"]\n",
    "\n",
    "print(\"‚úÖ Config created with proper audio config\")\n",
    "\n",
    "# Create model\n",
    "model = Vits(\n",
    "    config=config,\n",
    "    ap=ap,\n",
    "    tokenizer=tokenizer,\n",
    "    speaker_manager=None,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "print(f\"‚úÖ Model ready ({sum(p.numel() for p in model.parameters()):,} params)\")\n",
    "\n",
    "# Add this cell BEFORE creating the trainer (after model creation)\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "print(\"\\nüîß Configuring logging to disable file output...\")\n",
    "\n",
    "# Disable all file handlers for the trainer\n",
    "logging.getLogger(\"trainer\").handlers = []\n",
    "logging.getLogger(\"TTS\").handlers = []\n",
    "\n",
    "# Configure console-only logging\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "console_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Apply to relevant loggers\n",
    "for logger_name in [\"trainer\", \"TTS\"]:\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.handlers = [console_handler]\n",
    "    logger.propagate = False\n",
    "\n",
    "print(\"‚úÖ Logging configured for console output only\")\n",
    "\n",
    "# Create trainer with modified args\n",
    "trainer_args = TrainerArgs()\n",
    "trainer_args.use_accelerate = False  # Disable accelerate logging\n",
    "trainer_args.dashboard_logger = None  # Disable dashboard logging\n",
    "\n",
    "# CRITICAL: Close any existing log file handles before creating trainer\n",
    "import gc\n",
    "gc.collect()  # Force garbage collection to release file handles\n",
    "\n",
    "# Additional file cleanup: Close any open file handles in the output directory\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "def close_log_files(output_path):\n",
    "    \"\"\"Close any open log files in the output directory\"\"\"\n",
    "    try:\n",
    "        current_process = psutil.Process()\n",
    "        for file_handle in current_process.open_files():\n",
    "            if 'trainer_' in file_handle.path and output_path in file_handle.path:\n",
    "                try:\n",
    "                    os.close(file_handle.fd)\n",
    "                    print(f\"‚úÖ Closed file handle: {file_handle.path}\")\n",
    "                except:\n",
    "                    pass\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not close handles: {e}\")\n",
    "\n",
    "# Close any existing log files\n",
    "if os.path.exists(OUTPUT):\n",
    "    close_log_files(OUTPUT)\n",
    "\n",
    "# Alternative: Delete the output directory if it exists and recreate it\n",
    "if os.path.exists(OUTPUT):\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(OUTPUT, ignore_errors=True)\n",
    "        print(f\"‚úÖ Cleaned output directory: {OUTPUT}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not clean directory: {e}\")\n",
    "\n",
    "os.makedirs(OUTPUT, exist_ok=True)\n",
    "\n",
    "# Now create the trainer\n",
    "trainer = Trainer(\n",
    "    trainer_args,\n",
    "    config,\n",
    "    OUTPUT,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50bd44b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è VITS configuration...\n",
      "‚úÖ Config created\n"
     ]
    }
   ],
   "source": [
    "# ========== CELL 7: VITS Configuration (FIXED) ==========\n",
    "print(\"\\n‚öôÔ∏è VITS configuration...\")\n",
    "\n",
    "# Step 1: Create base config\n",
    "config = VitsConfig(\n",
    "    output_path=OUTPUT,\n",
    "    run_name=\"nepali_vits\",\n",
    ")\n",
    "\n",
    "# Step 2: Set attributes\n",
    "config.datasets = [dataset_config]\n",
    "config.audio = audio_config\n",
    "\n",
    "config.batch_size = 4\n",
    "config.eval_batch_size = 2\n",
    "config.num_loader_workers = 0\n",
    "config.num_eval_loader_workers = 0\n",
    "config.epochs = 100\n",
    "\n",
    "config.text_cleaner = \"basic_cleaners\"\n",
    "config.use_phonemes = False\n",
    "config.add_blank = True\n",
    "config.characters = None\n",
    "config.num_chars = len(tokenizer.characters.characters)\n",
    "\n",
    "config.optimizer = \"AdamW\"\n",
    "config.optimizer_params = {\"betas\": [0.8, 0.99], \"eps\": 1e-9, \"weight_decay\": 0.01}\n",
    "config.lr = 2e-4\n",
    "config.lr_scheduler = \"ExponentialLR\"\n",
    "config.lr_scheduler_params = {\"gamma\": 0.999875}\n",
    "\n",
    "config.print_step = 50\n",
    "config.plot_step = 0\n",
    "config.dashboard_logger = None\n",
    "config.save_step = 1000\n",
    "config.save_n_checkpoints = 5\n",
    "config.run_eval = True\n",
    "\n",
    "config.test_sentences = [\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\", \"‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶\"]\n",
    "\n",
    "print(\"‚úÖ Config created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40df9a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
      " --> C:\\Users\\ReticleX\\Pictures\\nepali_tts\\vits_output_v2\\nepali_vits-December-17-2025_10+42AM-0000000\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6082\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 106\n",
      " | > Min text length: 5\n",
      " | > Avg text length: 19.53666557053601\n",
      " | \n",
      " | > Max audio length: 154372.0\n",
      " | > Min audio length: 33097.0\n",
      " | > Avg audio length: 96163.91548832621\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "\n",
      "\u001b[1m > TRAINING (2025-12-17 10:42:24) \u001b[0m\n",
      "\n",
      "‚ùå Permission error: [WinError 32] The process cannot access the file because it is being used by another process: 'C:/Users/ReticleX/Pictures/nepali_tts/vits_output_v2/nepali_vits-December-17-2025_10+42AM-0000000\\\\trainer_0_log.txt'\n",
      "üí° Close programs using the output folder, or change output dir\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Start training\n",
    "    trainer.fit()\n",
    "    \n",
    "    print(\"\\nüéâ TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"üìÅ Checkpoints saved to: {OUTPUT}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
    "    try:\n",
    "        if hasattr(trainer, \"save_checkpoint\"):\n",
    "            trainer.save_checkpoint()\n",
    "        elif hasattr(trainer, \"model\") and hasattr(trainer.model, \"save_checkpoint\"):\n",
    "            trainer.model.save_checkpoint(OUTPUT)\n",
    "        print(\"‚úÖ Checkpoint saved\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not save checkpoint: {e}\")\n",
    "\n",
    "except ImportError as ie:\n",
    "    if \"torchcodec\" in str(ie):\n",
    "        print(\"\\n‚ùå Missing dependency: torchcodec\")\n",
    "        print(\"üí° Fix: pip install torchcodec or use librosa as backend\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Import error: {ie}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "except PermissionError as pe:\n",
    "    print(f\"\\n‚ùå Permission error: {pe}\")\n",
    "    print(\"üí° Close programs using the output folder, or change output dir\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
